{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshimaBagaria/Unsupervised_NetflixMoviesTvShowsClustering/blob/main/AB_Unsupervised_NetfixMoviesTvShowsClustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Netfix Movies and Tv Shows Clustering\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1     - Ashima Bagaria**\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/AshimaBagaria/Unsupervised_NetflixMoviesTvShowsClustering"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import math\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "from matplotlib.pyplot import figure\n",
        "import plotly.graph_objects as go\n",
        "import plotly.offline as py\n",
        "import plotly.express as px\n",
        "from datetime import datetime\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "try:\n",
        "  df_Master = pd.read_csv('/content/drive/MyDrive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')\n",
        "\n",
        "  df_Master_copy = df_Master                                                        #Creating a copy to preserve original data\n",
        "  #Return the first 5 rows of the DataFrame\n",
        "  df_Master.head()\n",
        "\n",
        "except:\n",
        "  print(\"There was a problem loading the file\")\n"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_Master.tail()"
      ],
      "metadata": {
        "id": "DzHvD1tqXhbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "# Dataset Rows & Columns count\n",
        "print('\\n', f'The number of rows dataset is : {df_Master.shape[0] }')\n",
        "print('\\n', f'The number of columns of the dataset is : {df_Master.shape[1] }')\n",
        "print('\\n', f'The dimension of the dataset is : {df_Master.shape }')            #To get number of rows and columns in the dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df_Master.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(\"Number of duplicate records = \" + str(len(df_Master[df_Master.duplicated()])))"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(df_Master.isna().any())                                           #Checking for columns with missing values"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as msno\n",
        "\n",
        "missingCount = df_Master.isna().sum()\n",
        "print(missingCount)\n",
        "\n",
        "# Visualize missing values as a matrix\n",
        "msno.matrix(df_Master)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df_Master.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df_Master.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable\n",
        "df_Master.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "\n",
        "\n",
        "#Handling the missing values\n",
        "\n",
        "df_Master[['director','country','cast']] = df_Master[['director','country','cast']].fillna('Unknown')\n",
        "df_Master['rating'] = df_Master['rating'].fillna(df_Master['rating'].mode()[0])                                                 #Assigning the most common rating to missing ratings\n",
        "\n",
        "# df_Master.dropna(axis=0, inplace = True)\n",
        "\n",
        "\n",
        "df_Master.isna().sum()\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##check for duplicates\n",
        "duplicates =len(df_Master[df_Master.duplicated()])\n",
        "print(duplicates)"
      ],
      "metadata": {
        "id": "Uk4ShlY0sQs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no duplicate records"
      ],
      "metadata": {
        "id": "2NXzMmM11gmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Master = df_Master.drop(['show_id'], axis=1)"
      ],
      "metadata": {
        "id": "gs_LHe4CHF3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Typecasting 'date_added' from string to datetime\n",
        "df_Master['month_added'] = pd.DatetimeIndex(df_Master['date_added']).month_name()"
      ],
      "metadata": {
        "id": "9izG29clPG3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigning the Ratings into grouped categories\n",
        "ratings = {\n",
        "    'TV-PG': 'Kids_6to12',\n",
        "    'TV-MA': 'Adults',\n",
        "    'TV-Y7-FV': 'Kids_6to12',\n",
        "    'TV-Y7': 'Kids_6to12',\n",
        "    'TV-14': 'Teenagers',\n",
        "    'R': 'Adults',\n",
        "    'TV-Y': 'Kids',\n",
        "    'NR': 'Adults',\n",
        "    'PG-13': 'Teenagers',\n",
        "    'TV-G': 'Kids',\n",
        "    'PG': 'Kids_6to12',\n",
        "    'G': 'Kids',\n",
        "    'UR': 'Adults',\n",
        "    'NC-17': 'Adults'\n",
        "}\n",
        "df_Master['target_ages'] = df_Master['rating'].replace(ratings)"
      ],
      "metadata": {
        "id": "FFbM73OOnubA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "\n",
        "print(\"*************************************************\")\n",
        "type_division = df_Master['type'].value_counts()\n",
        "print(type_division)\n",
        "print(\"*************************************************\\n\")\n",
        "\n",
        "# # define Seaborn color palette to use\n",
        "# palette_color = sns.color_palette('pastel')\n",
        "\n",
        "# fig = plt.figure(figsize=(4,4))\n",
        "# # plotting data on chart\n",
        "# plt.pie(type_division, colors=palette_color,labels =['Movie','TV Show'],  autopct='%.0f%%, explode=(0.0,0.1), shadow = True)\n",
        "# plt.title=\"Type of video\"\n",
        "\n",
        "\n",
        "type_division.plot.pie(title=\"Type of video\", legend=False,autopct='%1.1f%%', explode=(0.1,0.0),shadow=True, startangle=0,fontsize=12, colors = ['#ff9999','#66b3ff'])\n",
        "\n",
        "# displaying chart\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie charts show the size of items (called wedge) in one data series, proportional to the sum of the items. The data points in a pie chart are shown as a percentage of the whole pie. Since we wanted to understand what division of the total videos is movies and what is TV Shows, I chose a pie chart."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Netflix contains 69% movies and 31% television shows, indicating that movie shows have more content."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This could help business in decision making while buying rights for new movies or TV shows."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "\n",
        "TV_DF=df_Master[(df_Master['type']=='TV Show') & (df_Master['release_year'] >= 2010) & (df_Master['release_year'] < 2021)]       #Exclusing 2021 since 2021 has only 1 month data\n",
        "\n",
        "MOV_DF=df_Master[(df_Master['type']=='Movie') & (df_Master['release_year'] >= 2010) & (df_Master['release_year'] < 2021)]\n",
        "\n",
        "TV_DF = TV_DF['release_year'].value_counts().sort_index(ascending=False)\n",
        "MOV_DF = MOV_DF['release_year'].value_counts().sort_index(ascending=False)\n",
        "\n",
        "\n",
        "print(\"\\n TV Show Count\")\n",
        "print(TV_DF)\n",
        "\n",
        "print(\"\\n\\n Movie Count\")\n",
        "print(MOV_DF)\n",
        "\n",
        "# visualizing the movies and tv_shows based on the release year\n",
        "sns.set()\n",
        "TV_DF.plot( linewidth=3.5, color='lime',label=\"Movies / year\")\n",
        "MOV_DF.plot( linewidth=3.5, color='blue',label=\"TV Shows / year\")\n",
        "plt.xlabel=\"Years\"\n",
        "plt.ylabel=\"Releases\"\n",
        "plt.legend=['TV','Movie']\n",
        "# plt.xticks(df_Master['release_year'],['2019','2020'])\n",
        "\n",
        "plt.title=\"Production growth yearly\";\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "TV_DF=TV_DF.reset_index(name = 'count').sort_values(by='count',ascending=False)\n",
        "\n",
        "plt.figure(figsize=(7,3))\n",
        "plt.xlabel=\"Count\"\n",
        "plt.ylabel=\"Year\"\n",
        "plt.title=\"TV Shows per year\"\n",
        "plt.barh(TV_DF['index'],TV_DF['count'], color='yellowgreen')\n"
      ],
      "metadata": {
        "id": "2gkR5T_bw3s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOV_DF = MOV_DF.reset_index(name='count').sort_values(by='count',ascending=False)\n",
        "plt.xlabel =\"Count\"\n",
        "plt.ylabel=\"Year\"\n",
        "plt.title=\"Movies per year\"\n",
        "plt.figure(figsize=(7,3))\n",
        "plt.barh(MOV_DF['index'],MOV_DF['count'],color='coral')\n"
      ],
      "metadata": {
        "id": "bqh694n7xSqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chart - 3 visualization code\n",
        "from matplotlib import rcParams\n",
        "\n",
        "MOV_DF = df_Master[df_Master['type'] == 'Movie']\n",
        "TV_DF = df_Master[df_Master['type'] == 'TV Show']\n",
        "\n",
        "fig, ax =plt.subplots(1,2)\n",
        "sns.countplot(y=\"listed_in\", data=MOV_DF, order=MOV_DF['listed_in'].value_counts().index[0:15], ax=ax[0])\n",
        "\n",
        "sns.countplot(y=\"listed_in\", data=TV_DF, order=TV_DF['listed_in'].value_counts().index[0:15],ax=ax[1])\n",
        "rcParams['figure.figsize'] = 20,15\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "monthWiseData = df_Master['month_added'].value_counts(sort=True)\n",
        "list(monthWiseData.index)\n",
        "\n",
        "# plt.pie(monthWiseData, autopct='%.2f')\n",
        "plt.figure(figsize = (6,6))\n",
        "monthWiseData.plot.pie(title=\"Monthly distribution\", legend=False, \\\n",
        "                   autopct='%1.1f%%', explode=(0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05,0.05),shadow=False, startangle=0,fontsize=9,colors = ['#ff9999','#66b3ff','#99ff99','#ffcc99','#ff6666', '#ffcc99', '#99ff99', '#66b3ff', '#c2c2f0','#ffb3e6', '#c2c2f0','#ffb3e6'])\n",
        "\n",
        "plt.title= 'ANALYSIS ON MONTH ADDED'\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(14,4))\n",
        "sns.countplot(x='month_added', hue='type',lw=5, data=df_Master, ax=ax)"
      ],
      "metadata": {
        "id": "eWyGXdT_TaQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "\n",
        "x = df_Master['director'].value_counts().reset_index(name='count').sort_values(by='count',ascending=False)[1:10]\n",
        "\n",
        "#Movies as per directors\n",
        "plt.figure(figsize=(17,4))\n",
        "bar=plt.barh(x['index'],x['count'], color = 'grey')\n",
        "\n",
        "for index, value in enumerate(x['count']):\n",
        "    plt.text(value, index,\n",
        "             str(value))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_India = df_Master[(df_Master['country'] == 'India')]\n",
        "\n",
        "x = df_India['director'].value_counts().reset_index(name='count').sort_values(by='count',ascending=False)[1:11]\n",
        "\n",
        "#Indian Movies as per directors\n",
        "plt.figure(figsize=(17,3))\n",
        "plt.title='movie ratings'\n",
        "bar=plt.barh(x['index'],x['count'], color = 'olive')\n",
        "bar.xlabel = \"Count\"\n",
        "bar.ylabel=\"Director Name\"\n",
        "bar.title = \"Most movies by a director(India)\"\n",
        "\n",
        "for index, value in enumerate(x['count']):\n",
        "    plt.text(value, index,\n",
        "             str(value))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "n3qTeOrNQlRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "df_county_age =df_Master[(df_Master['country'].isin([\"India\",\"United States\",\"United Kingdom\"]))].groupby('country')['target_ages'].value_counts()\n",
        "\n",
        "print(df_county_age)\n",
        "print(\"\\n\\n\")\n",
        "#Plotting line graph to show trend over the years\n",
        "plt.rcParams['figure.figsize']=(10,4)\n",
        "df_county_age.plot(kind='bar', color = 'teal', linewidth = 6)\n",
        "plt.title='Total movies by age group in India, US and UK'\n",
        "\n",
        "#Assigning labels for x and y axis\n",
        "plt.ylabel='Movie count'\n",
        "plt.xlabel='Country,Age Group'"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_county_age =df_Master[(df_Master['country'].isin([\"India\",\"United States\",\"United Kingdom\"]))]\n",
        "\n",
        "# Preparing data for heatmap\n",
        "df_county_age['count'] = 1\n",
        "data = df_county_age.groupby('country')[['country','count']].sum().sort_values(by='count',ascending=False).reset_index()\n",
        "data = data['country']\n",
        "\n",
        "\n",
        "df_heatmap = df_county_age.loc[df_Master['country'].isin(data)]\n",
        "df_heatmap = pd.crosstab(df_heatmap['country'],df_heatmap['target_ages'],normalize = \"index\").T\n",
        "df_heatmap\n",
        "\n"
      ],
      "metadata": {
        "id": "ozPQAAxJc1dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5,5))\n",
        "\n",
        "country_order2 = ['United States', 'India', 'United Kingdom']\n",
        "age_order = ['Adults', 'Teenagers', 'Kids_6to12', 'Kids']\n",
        "\n",
        "# Plotting the heatmap\n",
        "sns.heatmap(df_heatmap.loc[age_order,country_order2],cmap=\"YlGnBu\", linewidth=2.5,cbar=False,annot=True,fmt='1.0%',vmax=.6,vmin=0.05,ax=ax,annot_kws={\"fontsize\":10})\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5KIIkcgDbY1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(df_Master[df_Master]"
      ],
      "metadata": {
        "id": "bhoIbf-JiZfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,2, figsize=(15,6))\n",
        "sns.distplot(MOV_DF['duration'].str.extract('(\\d+)'),kde=False, color=['red'],ax = ax[0])\n",
        "TV_DF['duration'] = TV_DF['duration'].str.replace(' Seasons','S')\n",
        "TV_DF['duration'] = TV_DF['duration'].str.replace(' Season','S')\n",
        "\n",
        "sns.countplot(x=TV_DF['duration'],data=TV_DF,order = TV_DF['duration'].value_counts().index,ax = ax[1])\n",
        "plt.title = 'Distplot with Normal distribution for Movies'\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chart 8"
      ],
      "metadata": {
        "id": "cyABhpMZMw9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = df_Master['country']\n",
        "wordcloud = WordCloud(width = 800,height = 500,background_color = 'floralwhite').generate(\" \".join(df_Master.country))\n",
        "fig = plt.figure(figsize = (10, 5),facecolor = 'b',edgecolor = 'k',)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gqypw2CJMzva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HO:Indian Movies are at least 2 hours (120 mins) long.**\n",
        "\n",
        "**H1:Indian Movies less than two hours long.**"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataHypo1 = df_Master[(df_Master['type'] == \"Movie\") & (df_Master['country'] == \"India\")]\n",
        "\n",
        "dataHypo1['duration'] = dataHypo1['duration'].str.replace('min','')\n",
        "dataHypo1['duration'] = pd.to_numeric(dataHypo1['duration'])\n",
        "\n",
        "M1 = dataHypo1['duration'].mean()\n",
        "S1 = dataHypo1['duration'].std()\n",
        "print(\"\\n*********************************************************************\")\n",
        "print(\"The average run time of Indian movies = \" + str(round(M1,2)) + \" Mins\")\n",
        "print(\"\\nThe Standard Deviation = \" + str(round(S1,2)) + \" Mins\")\n",
        "print(\"*********************************************************************\\n\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #import stats\n",
        "# from scipy import stats\n",
        "# #length of groups and DOF\n",
        "# n = len(dataHypo1)\n",
        "\n",
        "# dof = n - 1\n",
        "# print('DOF = ',dof)\n",
        "\n",
        "# sp_2 = ((n-1)*S1**2) / dof\n",
        "# print('SP_2 =',sp_2)\n",
        "\n",
        "# sp = np.sqrt(sp_2)\n",
        "# print('SP = ',sp)\n",
        "\n",
        "# #tvalue\n",
        "# t_val = (M1)/(sp * np.sqrt(1/n1))\n",
        "# print('tvalue = ',t_val)"
      ],
      "metadata": {
        "id": "a6RCLXELyn84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# stats.t.ppf(0.025,dof)"
      ],
      "metadata": {
        "id": "vJkOdYjaybxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stats.t.ppf(0.975,dof)"
      ],
      "metadata": {
        "id": "_T8CdrQM0Wc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# plotting graph\n",
        "fig,ax = plt.subplots(1,2, figsize=(15,10))\n",
        "\n",
        "# Display boxplot and dist plot.\n",
        "sns.distplot(x=df_Master['release_year'], ax=ax[0])\n",
        "sns.boxplot(df_Master.release_year)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "# Converting target ages and type(Movie/TV Series) to categorical data\n",
        "df_Master['type_cate'] = pd.Categorical(df_Master['type'])\n",
        "df_Master['age_cate'] = pd.Categorical(df_Master['target_ages'], categories=['Kids', 'Older Kids', 'Teens', 'Adults'])"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelling Approach:\n",
        "Select the attributes based on which you want to cluster the shows\n",
        "\n",
        "Text preprocessing: Remove all non-ascii characters, stopwords and punctuation marks, convert all textual data to lowercase\n",
        "\n",
        "Lemmatization to generate a meaningful word out of corpus of words\n",
        "Tokenization of corpus\n",
        "\n",
        "Word vectorization\n",
        "\n",
        "Dimensionality reduction\n",
        "\n",
        "Use different algorithms to cluster the movies, obtain the optimal number of clusters using different techniques\n",
        "\n",
        "Build an optimal number of clusters and visualise the contents of each cluster using word clouds"
      ],
      "metadata": {
        "id": "O5NT29oY9acL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df_Master[\"type\"] = le.fit_transform(df_Master[\"type\"])\n",
        "df_Master[\"country\"] = le.fit_transform(df_Master[\"country\"])\n",
        "\n",
        "df_Master['rating'] = le.fit_transform(df_Master['rating'])\n",
        "# df_Master['listed_in'] = le.fit_transform(df_Master['listed_in'])\n",
        "\n",
        "\n",
        "\n",
        "df_Master['clusteringFeature'] = (df_Master['description'] + ' '+ df_Master['listed_in'] )\n"
      ],
      "metadata": {
        "id": "3WJnfK5WtnN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Selecting features to create Bag of Words"
      ],
      "metadata": {
        "id": "xGA60OKKB907"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Expand Contraction\n",
        "!pip install contractions\n",
        "\n",
        "import contractions\n",
        "df_Master[\"expanded_desc\"]= df_Master['description'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
        "\n",
        "\n",
        "print(df_Master['description'][10])\n",
        "print(df_Master['expanded_desc'][10])\n"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "print(df_Master['clusteringFeature'][10])\n",
        "\n",
        "df_Master['clusteringFeature']= df_Master['clusteringFeature'].map(lambda x: x.lower())\n",
        "\n",
        "print(df_Master['clusteringFeature'][10])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_Master['clusteringFeature'][10])\n",
        "\n",
        "# Remove Punctuations\n",
        "import string\n",
        "\n",
        "# function to remove punctuations\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "        # replacing the punctuations with no space, which in effect deletes the punctuation marks\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)\n",
        "\n",
        "\n",
        "# applying above function on text feature\n",
        "df_Master['clusteringFeature']= df_Master['clusteringFeature'].apply(remove_punctuation)\n",
        "\n",
        "print(df_Master['clusteringFeature'][10])\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ntlk\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "# Remove Stopwords\n",
        "\n",
        "# extracting and displaying the stopwords from nltk library\n",
        "sw = stopwords.words('english')\n",
        "np.array(sw)\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_Master['clusteringFeature'][10])\n",
        "# function to remove stop words\n",
        "def stopwords(text):\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    return \" \".join(text)\n",
        "\n",
        "\n",
        "# Removing stop words\n",
        "df_Master['clusteringFeature'] = df_Master['clusteringFeature'].apply(stopwords)\n",
        "print(df_Master['clusteringFeature'][10])"
      ],
      "metadata": {
        "id": "Y2YmEiuSI9zj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LemmatizTION"
      ],
      "metadata": {
        "id": "a2hwTbtXgSMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to lemmatize the corpus\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "def lemmatize_verbs(words):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    lemmas = []\n",
        "    for word in words:\n",
        "        lemma = lemmatizer.lemmatize(word, pos='v')\n",
        "        lemmas.append(lemma)\n",
        "    return lemmas\n",
        "\n",
        "df_Master['clusteringFeature'] = lemmatize_verbs(df_Master['clusteringFeature'])\n"
      ],
      "metadata": {
        "id": "krAl2Sn6gWUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "print(df_Master['clusteringFeature'][10])\n",
        "tokenizer = TweetTokenizer()\n",
        "df_Master['clusteringFeature'] = df_Master['clusteringFeature'].apply(lambda x: tokenizer.tokenize(x))\n",
        "print(df_Master['clusteringFeature'][10])"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The process of converting words into numbers are called Vectorization."
      ],
      "metadata": {
        "id": "6PzkPcoMVZZ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert X into array form for clustering\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "\n",
        "\n",
        "df_Master.drop(columns=['title', 'cast', 'date_added', 'description'],axis=1)\n",
        "\n",
        "\n",
        "# clustering tokens saved in a variable\n",
        "clustering_data = df_Master['clusteringFeature']\n",
        "\n",
        "# Tokenization\n",
        "def identity_tokenizer(text):\n",
        "    return text\n",
        "\n",
        "# Using TFIDF vectorizer to vectorize the corpus\n",
        "tfidf = TfidfVectorizer(tokenizer=identity_tokenizer, stop_words='english', lowercase=False,max_features = 1000)\n",
        "X = tfidf.fit_transform(clustering_data)\n",
        "\n",
        "\n",
        "\n",
        "print(X.shape)\n",
        "\n",
        "\n",
        "# convert X into array form for clustering\n",
        "X = X.toarray()\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The TfidfVectorizer converts a collection of raw documents into a matrix of TF-IDF features.\n",
        "\n",
        "TF-IDF Vectorizer is a measure of originality of a word by comparing the number of times a word appears in document with the number of documents the word appears in\n",
        "\n",
        "The meaning increases proportionally to the number of times in the text a word appears but is compensated by the word frequency in the corpus (data-set)."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "\n",
        "# reducing the dimensions to 4000 using pca\n",
        "pca = PCA(n_components=500,random_state=50)\n",
        "pca.fit(X)\n",
        "\n",
        "# transformed features\n",
        "x_pca = pca.transform(X)\n",
        "# shape of transformed vectors\n",
        "print(x_pca.shape)\n",
        "\n",
        "# x_pca = X"
      ],
      "metadata": {
        "id": "FaDgZW0uqr2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Elbow method to find the optimal value of k\n",
        "wcss=[]\n",
        "for i in range(1,11):\n",
        "  print(i)\n",
        "  kmeans = KMeans(n_clusters=i,init='k-means++',random_state=33)\n",
        "  kmeans.fit(x_pca)\n",
        "  wcss_iter = kmeans.inertia_\n",
        "  wcss.append(wcss_iter)\n",
        "\n",
        "number_clusters = range(1,11)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.title = 'The Elbow Method - KMeans clustering'\n",
        "plt.xlabel ='Number of clusters'\n",
        "plt.ylabel='WCSS'\n",
        "plt.plot(number_clusters,wcss)\n"
      ],
      "metadata": {
        "id": "XkjhVuYR63F_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "#sillhoute score of clusters\n",
        "sill = []\n",
        "df = pd.DataFrame(columns=['Cluster','Score'])\n",
        "for i in range(2,11):\n",
        "    model = KMeans(n_clusters=i,init ='k-means++',random_state=42)\n",
        "    model.fit(x_pca)\n",
        "    y1 = model.predict(x_pca)\n",
        "    score = silhouette_score(X,y1)\n",
        "    df.loc[i-2] = [i,score]\n",
        "    print('cluster: %d \\t Sillhoute: %0.4f'%(i,score))"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Sillhoute's score\n",
        "\n",
        "# df.bar(df['Cluster'],df['Score'])\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.xlabel=\"Count\"\n",
        "plt.ylabel=\"Year\"\n",
        "plt.title=\"TV Shows per year\"\n",
        "plt.bar(df['Cluster'],df['Score'], color='yellowgreen')"
      ],
      "metadata": {
        "id": "omRuduWWLICu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the K-means model on a dataset\n",
        "kmeans = KMeans(n_clusters= 6, init='k-means++', random_state= 42)\n",
        "y_predict= kmeans.fit_predict(x_pca)\n",
        "\n",
        "score = silhouette_score(X, y_predict)\n",
        "print(\"Silhouette score is {}\".format(score))\n",
        "\n",
        "#davies_bouldin_score of our clusters\n",
        "from sklearn.metrics import davies_bouldin_score\n",
        "print(davies_bouldin_score(X, y_predict))\n",
        "\n",
        "df_Master[\"cluster\"] = y_predict"
      ],
      "metadata": {
        "id": "1rjQlpvYsHuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(15,6))\n",
        "sns.countplot(x='cluster', hue='type',lw=5, data=df_Master, ax=ax)"
      ],
      "metadata": {
        "id": "ygqMCx8LSNic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "\n",
        "\n",
        "def kmeans_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df_Master[df_Master['cluster']==cluster_num].clusteringFeature.values:\n",
        "      val = str(val)\n",
        "      tokens = val.split()\n",
        "\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  # wordcloud = WordCloud(width=1000, height=700,background_color ='azure',stopwords = stopwords).generate(comment_words)\n",
        "\n",
        "  fig = plt.figure(figsize=(10,5),facecolor = 'b',edgecolor = 'r')\n",
        "  wordcloud = WordCloud(width=1000, height=700,background_color ='azure',stopwords = stopwords).generate(comment_words)\n",
        "\n",
        "  plt.imshow(wordcloud,interpolation ='bilinear')\n",
        "  plt.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.savefig('country.png')\n",
        "  plt.show()\n",
        "\n",
        "kmeans_worldcloud(0)"
      ],
      "metadata": {
        "id": "EtZyD2y7W8uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  print(\"\\n\\n\\n CLUSTER NUMBER \"+ str( i+1) +\"\\n\\n\\n\")\n",
        "  kmeans_worldcloud(i)\n"
      ],
      "metadata": {
        "id": "miC1sjqKEUMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wUhBp-8AGrRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.cluster.hierarchy as shc\n",
        "plt.figure(figsize =(8, 5))\n",
        "plt.title='Visualising the data'\n",
        "plt.axhline(y= 10, color='r', linestyle='--')\n",
        "\n",
        "Dendrogram = shc.dendrogram((shc.linkage(x_pca, method ='ward')))"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Dendrogram)"
      ],
      "metadata": {
        "id": "DPaka6qgj0tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Dendrogram['color_list'])"
      ],
      "metadata": {
        "id": "Uqy0jRUMk9Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(set(Dendrogram['color_list']))"
      ],
      "metadata": {
        "id": "QinoI2eslvA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = len(set(Dendrogram['color_list']))-1\n",
        "\n",
        "n_clusters"
      ],
      "metadata": {
        "id": "vFvC7e3Ll5Ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "\n",
        "hierarchical = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward')\n",
        "hierarchical.fit_predict(x_pca)"
      ],
      "metadata": {
        "id": "QSLrFfFEmMUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hierarchical"
      ],
      "metadata": {
        "id": "Ru0GMoV-pN3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a kmeans cluster number attribute\n",
        "df_Master['hierarchical_cluster'] = hierarchical.labels_\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.countplot(x='hierarchical_cluster', hue='type',lw=5, data=df_Master, ax=ax)"
      ],
      "metadata": {
        "id": "9TNcpyDNppgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a wordcloud for the movie descriptions\n",
        "def hierarchical_worldcloud(cluster_num):\n",
        "  comment_words = ''\n",
        "  stopwords = set(STOPWORDS)\n",
        "\n",
        "  # iterate through the csv file\n",
        "  for val in df_Master[df_Master['hierarchical_cluster']==cluster_num].clusteringFeature.values:\n",
        "      val = str(val)\n",
        "      tokens = val.split()\n",
        "      for i in range(len(tokens)):\n",
        "          tokens[i] = tokens[i].lower()\n",
        "\n",
        "      comment_words += \" \".join(tokens)+\" \"\n",
        "\n",
        "  wordcloud = WordCloud(width = 700, height = 700,background_color ='azure',stopwords = stopwords,min_font_size = 8).generate(comment_words)\n",
        "  print(\"\\n\\n\\n CLUSTER NUMBER \"+ str( cluster_num+1) +\"\\n\\n\\n\")\n",
        "\n",
        "  # plot the WordCloud image\n",
        "  plt.figure(figsize = (8,5))\n",
        "  plt.imshow(wordcloud)\n",
        "  plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "OwPYcejLqLWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hierarchical_worldcloud(0)"
      ],
      "metadata": {
        "id": "eIZkymjPqzNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hierarchical_worldcloud(1)"
      ],
      "metadata": {
        "id": "rNvq5PqKrzeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hierarchical_worldcloud(2)"
      ],
      "metadata": {
        "id": "6kFSGlIEsV_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*italicised text*###9. Building Content based recommender system:"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)*** RECOMMENDER SYSTEM"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# converting tokens to string\n",
        "\n",
        "def convert(lst):\n",
        "  return ' '.join(lst)\n",
        "\n",
        "df_Master['clusteringFeature'] = df_Master['clusteringFeature'].apply(lambda x: convert(x))\n",
        "\n",
        "# setting title of movies/Tv shows as index\n",
        "df_Master.set_index('title',inplace=True)\n",
        "\n",
        "\n",
        "CV = CountVectorizer()\n",
        "converted_matrix = CV.fit_transform(df_Master['clusteringFeature'])\n",
        "\n",
        "\n",
        "cosine_similarity = cosine_similarity(converted_matrix)\n",
        "\n",
        "\n",
        "\n",
        "cosine_similarity.shape\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3uzHOQlcspu6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Developing a function to get 10 recommendations for a show\n",
        "indices = pd.Series(df_Master.index)\n",
        "\n",
        "def recommend_top10(title, cosine_sim = cosine_similarity):\n",
        "  try:\n",
        "    recommend_content = []\n",
        "    idx = indices[indices == title].index[0]\n",
        "    series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
        "    top10 = list(series.iloc[1:11].index)\n",
        "\n",
        "    # list with the titles of the best 10 matching movies\n",
        "    for i in top10:\n",
        "      recommend_content.append(list(df_Master.index)[i])\n",
        "    print(\"If you like this '\"+title+\"', you may also enjoy:\\n\")\n",
        "    return recommend_content\n",
        "\n",
        "  except:\n",
        "    return 'Movie not found'"
      ],
      "metadata": {
        "id": "VM4JHu54t6fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommendations for 'A Man Called God'\n",
        "recommend_top10('Hamara Dil Aapke Paas Hai')"
      ],
      "metadata": {
        "id": "MN8QdMTgt9Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}